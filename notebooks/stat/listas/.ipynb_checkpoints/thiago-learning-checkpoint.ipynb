{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ler csv\n",
    "Agrupar pela coluna weekday\n",
    "contar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql import functions as F, types as T\n",
    "import datetime\n",
    "import sys\n",
    "from pyspark.sql import DataFrame, Row, SparkSession\n",
    "import datetime\n",
    "from pyspark.sql.functions import col, trim, to_date, desc, last, rank\n",
    "import os\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_tipo_fundo = spark.createDataFrame([\n",
    "    ('256', '2019-03-27', '2019-03-27'),\n",
    "    ('273', '2019-11-03',  None),\n",
    "    ('311', '2019-11-01',  None),\n",
    "    ('312', '2019-11-01',  None),\n",
    "    ('400', '2019-11-01',  None),\n",
    "],[\"tipo_fundo_codigo\", \"tipo_fundo_data_inicio\",\"tipo_fundo_data_fim\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "fato_transferencia = spark.createDataFrame([\n",
    "    ('256',  None,  '2019-10-30', 'A'),\n",
    "    ('256', '256', '2019-10-31', 'A'),\n",
    "    ('311', '256', '2019-11-01', 'A'),\n",
    "    ('311', '311', '2019-11-02', 'A'),\n",
    "    ('273', '311', '2019-11-03', 'A'),\n",
    "    ('400', '273', '2019-11-04', 'A'),\n",
    "    ('256',  None, '2019-10-30', 'B'),\n",
    "    ('256', '256', '2019-10-31', 'B'),\n",
    "    ('312', '256', '2019-11-01', 'B'),\n",
    "    ('312', '312', '2019-11-02', 'B'),\n",
    "    ('312', '312', '2019-11-03', 'B'),\n",
    "    ('400', '312', '2019-11-04', 'B'),\n",
    "    ('400', '400', '2019-11-05', 'B'),\n",
    "    ('400', '400', '2019-11-06', 'B'),\n",
    "    ('400', '400', '2019-11-07', 'B'),\n",
    "    ('273',  None, '2019-10-30', 'C'),\n",
    "    ('273', '273', '2019-10-31', 'C'),\n",
    "    ('273', '273', '2019-11-01', 'C'),\n",
    "    ('311', '273', '2019-11-02', 'C'),\n",
    "    ('311', '311', '2019-11-03', 'C'),\n",
    "    ('311', '311', '2019-11-04', 'C'),\n",
    "    ('311', '311', '2019-11-05', 'C'),\n",
    "    ('311', '311', '2019-11-06', 'C'),\n",
    "#     ('311', '256', '2019-11-01', 'C'),\n",
    "\n",
    "    \n",
    "],['codtipo', 'codtipo_anterior', 'data', 'codfundo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fato_transferencia.alias('l').join(dim_tipo_fundo.alias('r'),\n",
    "    col('l.codtipo_anterior') == col('r.tipo_fundo_codigo') , 'left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = dataset.withColumn(\"aux_column\",\n",
    "     when( ( col(\"codtipo\") != col(\"codtipo_anterior\") ) &\n",
    "             ( col('tipo_fundo_data_fim').isNotNull() )  \n",
    "            , col(\"codtipo\")  )\\\n",
    "     .otherwise(None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dataset = dataset.withColumn(\"aux_column\",\n",
    "#      when( ( (col(\"codtipo\") != col(\"codtipo_anterior\")) &\n",
    "#              ( col('tipo_fundo_data_fim').isNotNull() ) \n",
    "#            ) | ( (col(\"codtipo_anterior\").isNull()) & \n",
    "#                  (col('tipo_fundo_data_fim').isNull())\n",
    "#                ) , col(\"codtipo\")  )\\\n",
    "#      .otherwise(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy([\"codfundo\"]).orderBy(desc('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------+--------+----------------------+-------------------+---------+\n",
      "|codtipo|codtipo_anterior|      data|codfundo|tipo_fundo_data_inicio|tipo_fundo_data_fim|novo_tipo|\n",
      "+-------+----------------+----------+--------+----------------------+-------------------+---------+\n",
      "|    256|            null|2019-10-30|       A|                  null|               null|      311|\n",
      "|    256|             256|2019-10-31|       A|            2019-03-27|         2019-03-27|      311|\n",
      "|    311|             256|2019-11-01|       A|            2019-03-27|         2019-03-27|      311|\n",
      "|    311|             311|2019-11-02|       A|            2019-11-01|               null|      311|\n",
      "|    273|             311|2019-11-03|       A|            2019-11-01|               null|      273|\n",
      "|    400|             273|2019-11-04|       A|            2019-11-03|               null|      400|\n",
      "|    256|            null|2019-10-30|       B|                  null|               null|      312|\n",
      "|    256|             256|2019-10-31|       B|            2019-03-27|         2019-03-27|      312|\n",
      "|    312|             256|2019-11-01|       B|            2019-03-27|         2019-03-27|      312|\n",
      "|    312|             312|2019-11-02|       B|            2019-11-01|               null|      312|\n",
      "|    312|             312|2019-11-03|       B|            2019-11-01|               null|      312|\n",
      "|    400|             312|2019-11-04|       B|            2019-11-01|               null|      400|\n",
      "|    400|             400|2019-11-05|       B|            2019-11-01|               null|      400|\n",
      "|    400|             400|2019-11-06|       B|            2019-11-01|               null|      400|\n",
      "|    400|             400|2019-11-07|       B|            2019-11-01|               null|      400|\n",
      "|    256|            null|2019-10-30|       C|                  null|               null|     null|\n",
      "|    256|             256|2019-10-31|       C|            2019-03-27|         2019-03-27|     null|\n",
      "+-------+----------------+----------+--------+----------------------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste = new_dataset.withColumn(\"novo_tipo\", \n",
    "    when( (\n",
    "            ( col(\"tipo_fundo_data_fim\").isNull() ) &\n",
    "            ( col(\"codtipo_anterior\").isNotNull() )\n",
    "          ), col('codtipo') )\\\n",
    "        .otherwise( F.first('aux_column', True).over(window) ) )\\\n",
    "            .orderBy('codfundo','data')\n",
    "\n",
    "\n",
    "teste.select([\"codtipo\", \n",
    "              \"codtipo_anterior\",\n",
    "              \"data\",\n",
    "              \"codfundo\", \n",
    "              \"tipo_fundo_data_inicio\",\n",
    "              \"tipo_fundo_data_fim\",\n",
    "              \"novo_tipo\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------+--------+-----------------+----------------------+-------------------+------------+\n",
      "|codtipo|codtipo_anterior|      data|codfundo|tipo_fundo_codigo|tipo_fundo_data_inicio|tipo_fundo_data_fim|novo_codtipo|\n",
      "+-------+----------------+----------+--------+-----------------+----------------------+-------------------+------------+\n",
      "|    256|            null|2019-10-30|       A|             null|                  null|               null|         256|\n",
      "|    256|            null|2019-10-30|       B|             null|                  null|               null|         256|\n",
      "|    256|             256|2019-10-31|       B|              256|            2019-03-27|         2019-03-27|         400|\n",
      "|    256|             256|2019-10-31|       A|              256|            2019-03-27|         2019-03-27|         400|\n",
      "|    311|             256|2019-11-01|       A|              256|            2019-03-27|         2019-03-27|         400|\n",
      "|    312|             256|2019-11-01|       B|              256|            2019-03-27|         2019-03-27|         400|\n",
      "|    311|             311|2019-11-02|       A|              311|            2019-11-01|               null|         311|\n",
      "|    312|             312|2019-11-02|       B|              312|            2019-11-01|               null|         312|\n",
      "|    312|             312|2019-11-03|       B|              312|            2019-11-01|               null|         312|\n",
      "|    273|             311|2019-11-03|       A|              311|            2019-11-01|               null|         273|\n",
      "|    400|             273|2019-11-04|       A|              273|            2019-11-03|               null|         400|\n",
      "|    400|             312|2019-11-04|       B|              312|            2019-11-01|               null|         400|\n",
      "|    400|             400|2019-11-05|       B|              400|            2019-11-01|               null|         400|\n",
      "|    400|             400|2019-11-06|       B|              400|            2019-11-01|               null|         400|\n",
      "|    400|             400|2019-11-07|       B|              400|            2019-11-01|               null|         400|\n",
      "+-------+----------------+----------+--------+-----------------+----------------------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy([\"codfundo\"]).orderBy(desc(\"data\"))\n",
    "\n",
    "new_dataset = dataset.withColumn(\"novo_codtipo\", \n",
    "    when( col(\"tipo_fundo_data_fim\").isNull(), col(\"codtipo\") )\\\n",
    "        .otherwise( F.first(\"codtipo\").over( window )) ).orderBy('data').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_tipo_fundo = spark.read.parquet('dim_tipo_fundo')\n",
    "dim_tipo_fundo = dim_tipo_fundo.select([col('tipo_fundo_codigo').cast(StringType()),\n",
    "                                        'tipo_fundo_data_inicio', 'tipo_fundo_data_fim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_tipo_fundo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_tipo_fundo = spark.createDataFrame([\n",
    "    (256, datetime.datetime.strptime(\"2020-01-01\", \"%Y-%m-%d\"), datetime.datetime.strptime(\"2020-01-31\", \"%Y-%m-%d\"), \"1\" ),\n",
    "    (256, datetime.datetime.strptime(\"2020-01-01\", \"%Y-%m-%d\"), datetime.datetime.strptime(\"2020-01-31\", \"%Y-%m-%d\"), \"2\" ),\n",
    "    (258, datetime.datetime.strptime(\"2020-01-01\", \"%Y-%m-%d\"), datetime.datetime.strptime(\"2020-01-31\", \"%Y-%m-%d\"), \"4\" ),\n",
    "    (311, datetime.datetime.strptime(\"2020-02-01\", \"%Y-%m-%d\"), datetime.datetime.strptime(\"2020-02-29\", \"%Y-%m-%d\"), \"1\" ),\n",
    "    (313, datetime.datetime.strptime(\"2020-03-01\", \"%Y-%m-%d\"), None, \"1\" ),\n",
    "    (317, datetime.datetime.strptime(\"2020-02-01\", \"%Y-%m-%d\"), None, \"2\" ),\n",
    "    (318, datetime.datetime.strptime(\"2020-02-01\", \"%Y-%m-%d\"), None, \"3\" ),\n",
    "],[\"codtipo\", \"data\", \"datafim\", \"codfundo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.createDataFrame([\n",
    "    (1, datetime.datetime.strptime(\"2019-03-01\", \"%Y-%m-%d\"),   10, datetime.datetime.strptime(\"2018-03-01\", \"%Y-%m-%d\")),\n",
    "    (1, datetime.datetime.strptime(\"2020-03-02\", \"%Y-%m-%d\"),   20, datetime.datetime.strptime(\"2019-03-01\", \"%Y-%m-%d\")),\n",
    "    (1, datetime.datetime.strptime(\"2020-03-27\", \"%Y-%m-%d\"),   20, datetime.datetime.strptime(\"2019-03-27\", \"%Y-%m-%d\")),\n",
    "    (2, datetime.datetime.strptime(\"2019-03-01\", \"%Y-%m-%d\"),   15, datetime.datetime.strptime(\"2018-03-01\", \"%Y-%m-%d\")),\n",
    "    (2, datetime.datetime.strptime(\"2019-02-28\", \"%Y-%m-%d\"),   10, datetime.datetime.strptime(\"2018-02-28\", \"%Y-%m-%d\")),\n",
    "    (2, datetime.datetime.strptime(\"2020-03-02\", \"%Y-%m-%d\"),   10, datetime.datetime.strptime(\"2019-03-01\", \"%Y-%m-%d\")),\n",
    "    (3, datetime.datetime.strptime(\"2019-03-01\", \"%Y-%m-%d\"), None, datetime.datetime.strptime(\"2018-03-01\", \"%Y-%m-%d\")),\n",
    "    (3, datetime.datetime.strptime(\"2019-02-28\", \"%Y-%m-%d\"),   10, datetime.datetime.strptime(\"2018-02-28\", \"%Y-%m-%d\")),\n",
    "    (3, datetime.datetime.strptime(\"2020-03-02\", \"%Y-%m-%d\"),   10, datetime.datetime.strptime(\"2019-03-01\", \"%Y-%m-%d\")),\n",
    "    (4, datetime.datetime.strptime(\"2019-03-01\", \"%Y-%m-%d\"),    0, datetime.datetime.strptime(\"2018-03-01\", \"%Y-%m-%d\")),\n",
    "    (4, datetime.datetime.strptime(\"2019-02-28\", \"%Y-%m-%d\"),   10, datetime.datetime.strptime(\"2018-02-28\", \"%Y-%m-%d\")),\n",
    "    (4, datetime.datetime.strptime(\"2020-03-02\", \"%Y-%m-%d\"),   10, datetime.datetime.strptime(\"2019-03-01\", \"%Y-%m-%d\"))\n",
    "],[\"codfundo\", \"data\", \"captacao_liquida\", \"ULTIMOS_12_MESES_DT\"]).drop('ULTIMOS_12_MESES_DT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "window365 = Window.partitionBy(['codfundo']).orderBy(unix_timestamp(col('data'))).rangeBetween(-365 * 86400, Window.currentRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------------+-------------+----+--------+---------------------+\n",
      "|codfundo|               data|captacao_liquida|less_one_year|diff|   teste|sum_capitacao_liquida|\n",
      "+--------+-------------------+----------------+-------------+----+--------+---------------------+\n",
      "|       1|2019-03-01 00:00:00|              10|   2018-03-01| 365|    [10]|                   10|\n",
      "|       1|2020-03-02 00:00:00|              20|   2019-03-02| 366|    [20]|                   20|\n",
      "|       1|2020-03-27 00:00:00|              20|   2019-03-27| 366|[20, 20]|                   40|\n",
      "|       3|2019-02-28 00:00:00|              10|   2018-02-28| 365|    [10]|                   10|\n",
      "|       3|2019-03-01 00:00:00|            null|   2018-03-01| 365|    [10]|                   10|\n",
      "|       3|2020-03-02 00:00:00|              10|   2019-03-02| 366|    [10]|                   10|\n",
      "|       2|2019-02-28 00:00:00|              10|   2018-02-28| 365|    [10]|                   10|\n",
      "|       2|2019-03-01 00:00:00|              15|   2018-03-01| 365|[10, 15]|                   25|\n",
      "|       2|2020-03-02 00:00:00|              10|   2019-03-02| 366|    [10]|                   10|\n",
      "|       4|2019-02-28 00:00:00|              10|   2018-02-28| 365|    [10]|                   10|\n",
      "|       4|2019-03-01 00:00:00|               0|   2018-03-01| 365| [10, 0]|                   10|\n",
      "|       4|2020-03-02 00:00:00|              10|   2019-03-02| 366|    [10]|                   10|\n",
      "+--------+-------------------+----------------+-------------+----+--------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.withColumn(\"less_one_year\", F.add_months(col('data'), -12))\\\n",
    "    .withColumn(\"diff\", datediff(col('data'), F.add_months(col('data'), -12)))\\\n",
    "    .withColumn(\"teste\", F.collect_list('captacao_liquida').over(window365))\\\n",
    "    .withColumn(\"sum_capitacao_liquida\", F.sum('captacao_liquida').over(window365)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Window.partitionBy(['codfundo']).orderBy(col('data').cast(\"timestamp\").cast(\"long\")).rangeBetween(-365 * 86400, Window.currentRow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------+-----+\n",
      "|codtipo|               data|codfundo|teste|\n",
      "+-------+-------------------+--------+-----+\n",
      "|    318|2020-02-01 00:00:00|       3|  3.0|\n",
      "|    256|2020-01-01 00:00:00|       1|  1.0|\n",
      "|    311|2020-02-01 00:00:00|       1|  1.0|\n",
      "|    313|2020-03-01 00:00:00|       1|  1.0|\n",
      "|    258|2020-01-01 00:00:00|       4|  4.0|\n",
      "|    256|2020-01-01 00:00:00|       2|  2.0|\n",
      "|    317|2020-02-01 00:00:00|       2|  2.0|\n",
      "+-------+-------------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.withColumn(\"teste\", F.sum('codfundo').over(window)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_tipo_fundo = spark.createDataFrame([\n",
    "    (256, datetime.datetime.strptime(\"2020-01-01\", \"%Y-%m-%d\"), datetime.datetime.strptime(\"2020-01-31\", \"%Y-%m-%d\"), \"1\" ),\n",
    "    (256, datetime.datetime.strptime(\"2020-01-01\", \"%Y-%m-%d\"), datetime.datetime.strptime(\"2020-01-31\", \"%Y-%m-%d\"), \"2\" ),\n",
    "    (258, datetime.datetime.strptime(\"2020-01-01\", \"%Y-%m-%d\"), datetime.datetime.strptime(\"2020-01-31\", \"%Y-%m-%d\"), \"4\" ),\n",
    "    (311, datetime.datetime.strptime(\"2020-02-01\", \"%Y-%m-%d\"), datetime.datetime.strptime(\"2020-02-29\", \"%Y-%m-%d\"), \"1\" ),\n",
    "    (313, datetime.datetime.strptime(\"2020-03-01\", \"%Y-%m-%d\"), None, \"1\" ),\n",
    "    (317, datetime.datetime.strptime(\"2020-02-01\", \"%Y-%m-%d\"), None, \"2\" ),\n",
    "    (318, datetime.datetime.strptime(\"2020-02-01\", \"%Y-%m-%d\"), None, \"3\" ),\n",
    "],[\"codtipo\", \"data\", \"datafim\", \"codfundo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------+------------+\n",
      "|codtipo|               data|codfundo|novo_codtipo|\n",
      "+-------+-------------------+--------+------------+\n",
      "|    256|2020-01-01 00:00:00|       1|         313|\n",
      "|    256|2020-01-01 00:00:00|       2|         317|\n",
      "|    258|2020-01-01 00:00:00|       4|         258|\n",
      "|    311|2020-02-01 00:00:00|       1|         313|\n",
      "|    313|2020-03-01 00:00:00|       1|         313|\n",
      "|    317|2020-02-01 00:00:00|       2|         317|\n",
      "|    318|2020-02-01 00:00:00|       3|         318|\n",
      "+-------+-------------------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = Window.partitionBy([\"codfundo\"]).orderBy(desc(\"data\"))\n",
    "dataset.withColumn(\"novo_codtipo\", F.first(\"codtipo\").over(a)).orderBy(\"codtipo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/opt/dna-qualicorp/notebooks/stat/datasets/hour.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- instant: string (nullable = true)\n",
      " |-- dteday: string (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- yr: string (nullable = true)\n",
      " |-- mnth: string (nullable = true)\n",
      " |-- hr: string (nullable = true)\n",
      " |-- holiday: string (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- workingday: string (nullable = true)\n",
      " |-- weathersit: string (nullable = true)\n",
      " |-- temp: string (nullable = true)\n",
      " |-- atemp: string (nullable = true)\n",
      " |-- hum: string (nullable = true)\n",
      " |-- windspeed: string (nullable = true)\n",
      " |-- casual: string (nullable = true)\n",
      " |-- registered: string (nullable = true)\n",
      " |-- cnt: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weekday|count|\n",
      "+-------+-----+\n",
      "|      3| 2475|\n",
      "|      0| 2502|\n",
      "|      5| 2487|\n",
      "|      6| 2512|\n",
      "|      1| 2479|\n",
      "|      4| 2471|\n",
      "|      2| 2453|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('weekday').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17379"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|weekday|\n",
      "+-------+\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "|      6|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('weekday').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+------+----------+---+\n",
      "|instant|    dteday|season| yr|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed|casual|registered|cnt|\n",
      "+-------+----------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+------+----------+---+\n",
      "|      1|2011-01-01|     1|  0|   1|  0|      0|      6|         0|         1|0.24|0.2879|0.81|        0|     3|        13| 16|\n",
      "|      2|2011-01-01|     1|  0|   1|  1|      0|      6|         0|         1|0.22|0.2727| 0.8|        0|     8|        32| 40|\n",
      "+-------+----------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+------+----------+---+\n",
      "only showing top 2 rows\n",
      "\n",
      "StructType(List(StructField(instant,StringType,true),StructField(dteday,StringType,true),StructField(season,StringType,true),StructField(yr,StringType,true),StructField(mnth,StringType,true),StructField(hr,StringType,true),StructField(holiday,StringType,true),StructField(weekday,StringType,true),StructField(workingday,StringType,true),StructField(weathersit,StringType,true),StructField(temp,StringType,true),StructField(atemp,StringType,true),StructField(hum,StringType,true),StructField(windspeed,StringType,true),StructField(casual,StringType,true),StructField(registered,StringType,true),StructField(cnt,StringType,true))) hi\n",
      "+-------+\n",
      "|weekday|\n",
      "+-------+\n",
      "|    6.0|\n",
      "|    6.0|\n",
      "|    6.0|\n",
      "|    6.0|\n",
      "+-------+\n",
      "only showing top 4 rows\n",
      "\n",
      "root\n",
      " |-- instant: string (nullable = true)\n",
      " |-- dteday: string (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- yr: string (nullable = true)\n",
      " |-- mnth: string (nullable = true)\n",
      " |-- hr: string (nullable = true)\n",
      " |-- holiday: string (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- workingday: string (nullable = true)\n",
      " |-- weathersit: string (nullable = true)\n",
      " |-- temp: string (nullable = true)\n",
      " |-- atemp: string (nullable = true)\n",
      " |-- hum: string (nullable = true)\n",
      " |-- windspeed: string (nullable = true)\n",
      " |-- casual: string (nullable = true)\n",
      " |-- registered: string (nullable = true)\n",
      " |-- cnt: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.columns\n",
    "df.show(2)\n",
    "print(df.schema, 'hi')\n",
    "df.select([F.col(c).cast('double') for c in df.columns if c in ['weekday']]).show(4)\n",
    "df.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
